{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# lib\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# preprocessing\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# training\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n# metric\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\n# model\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nimport catboost\nfrom catboost import CatBoostClassifier\n\n# model save & load\nimport joblib \nfrom tensorflow.keras.models import load_model\n\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-12T12:13:35.69973Z","iopub.execute_input":"2021-12-12T12:13:35.700069Z","iopub.status.idle":"2021-12-12T12:13:43.713108Z","shell.execute_reply.started":"2021-12-12T12:13:35.699993Z","shell.execute_reply":"2021-12-12T12:13:43.712236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# reduce memory\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() / 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:43.714856Z","iopub.execute_input":"2021-12-12T12:13:43.715178Z","iopub.status.idle":"2021-12-12T12:13:43.726645Z","shell.execute_reply.started":"2021-12-12T12:13:43.715143Z","shell.execute_reply":"2021-12-12T12:13:43.726009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"og_test = pd.read_csv('../input/traintest/fp_test_dataset.csv')\nog_train = pd.read_csv('../input/traintest/fp_train_dataset.csv')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:43.727899Z","iopub.execute_input":"2021-12-12T12:13:43.728245Z","iopub.status.idle":"2021-12-12T12:13:50.714502Z","shell.execute_reply.started":"2021-12-12T12:13:43.728215Z","shell.execute_reply":"2021-12-12T12:13:50.713776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"og_test = reduce_mem_usage(og_test)\nog_train = reduce_mem_usage(og_train)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:50.718098Z","iopub.execute_input":"2021-12-12T12:13:50.718301Z","iopub.status.idle":"2021-12-12T12:13:51.818244Z","shell.execute_reply.started":"2021-12-12T12:13:50.718276Z","shell.execute_reply":"2021-12-12T12:13:51.81739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"원본 데이터셋을 합쳐서 특정 컬럼을 드랍하고 레이블 인코딩을 하는 등 전처리 과정이 필요했습니다.  \n때문에 전처리 전의 데이터셋은 'og_'라는 단어를 앞에 붙여서 표기했습니다.","metadata":{}},{"cell_type":"code","source":"print(og_train.shape)\nog_train","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:51.819888Z","iopub.execute_input":"2021-12-12T12:13:51.82044Z","iopub.status.idle":"2021-12-12T12:13:52.034635Z","shell.execute_reply.started":"2021-12-12T12:13:51.820396Z","shell.execute_reply":"2021-12-12T12:13:52.033077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(og_test.shape)\nog_test","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:52.035851Z","iopub.execute_input":"2021-12-12T12:13:52.036195Z","iopub.status.idle":"2021-12-12T12:13:52.103425Z","shell.execute_reply.started":"2021-12-12T12:13:52.036157Z","shell.execute_reply":"2021-12-12T12:13:52.102305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"og_train.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:52.104673Z","iopub.execute_input":"2021-12-12T12:13:52.10536Z","iopub.status.idle":"2021-12-12T12:13:52.1131Z","shell.execute_reply.started":"2021-12-12T12:13:52.105323Z","shell.execute_reply":"2021-12-12T12:13:52.112389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = pd.concat([og_train, og_test])\ndataset.reset_index(drop = True, inplace = True)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:52.114078Z","iopub.execute_input":"2021-12-12T12:13:52.114286Z","iopub.status.idle":"2021-12-12T12:13:52.6217Z","shell.execute_reply.started":"2021-12-12T12:13:52.114262Z","shell.execute_reply":"2021-12-12T12:13:52.62101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"전처리를 위해 하나의 데이터셋으로 만들어야 했기 때문에 train/test 데이터셋을 세로 방향으로 합칩니다.  ","metadata":{}},{"cell_type":"code","source":"dataset.drop(['Unnamed: 0', 'server_time_kst', 'device_type', 'content_name', 'content_keyword'], axis = 1, inplace = True)\ndataset","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:52.622699Z","iopub.execute_input":"2021-12-12T12:13:52.623152Z","iopub.status.idle":"2021-12-12T12:13:53.053175Z","shell.execute_reply.started":"2021-12-12T12:13:52.623108Z","shell.execute_reply":"2021-12-12T12:13:53.052397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모든 값이 통일 된 값을 갖고 있는 device_type와 학습에 불필요하다고 판단되거나 EDA과정에서 학습에서 제외하기로 정한 content_name, content_keyword, server_time_kst 컬럼을 드랍합니다.","metadata":{}},{"cell_type":"code","source":"dataset.columns","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:53.056875Z","iopub.execute_input":"2021-12-12T12:13:53.063351Z","iopub.status.idle":"2021-12-12T12:13:53.074493Z","shell.execute_reply.started":"2021-12-12T12:13:53.063309Z","shell.execute_reply":"2021-12-12T12:13:53.073721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"위에 출력된 컬럼들이 모델에 들어갈 컬럼들입니다.","metadata":{}},{"cell_type":"code","source":"# label encoding\ncategorical_features = ['imp_id', 'content_id', 'c_user_gender', 'content_flag_used', 'c_content_category_id_1',\n                       'c_content_category_id_2', 'c_content_category_id_3', 'hour']\n\nfor feat in categorical_features:\n    lbe = LabelEncoder()\n    dataset[feat] = lbe.fit_transform(dataset[feat])  \n\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:53.076693Z","iopub.execute_input":"2021-12-12T12:13:53.077841Z","iopub.status.idle":"2021-12-12T12:13:54.966809Z","shell.execute_reply.started":"2021-12-12T12:13:53.077693Z","shell.execute_reply":"2021-12-12T12:13:54.965893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"categorical feature를 label encoding합니다. catboost를 제외한 나머지 앙상블 모델의 경우 numeric한 feature만 사용이 가능하기 때문에  \none-hot encoding을 하거나 label encoding을 해주어야합니다.  ","metadata":{}},{"cell_type":"code","source":"dataset.info()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:54.968245Z","iopub.execute_input":"2021-12-12T12:13:54.96852Z","iopub.status.idle":"2021-12-12T12:13:55.022603Z","shell.execute_reply.started":"2021-12-12T12:13:54.968483Z","shell.execute_reply":"2021-12-12T12:13:55.021824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"위 과정을 거쳐 Ensemble Model에 적용이 가능한 데이터셋이 완성되게 됩니다.","metadata":{}},{"cell_type":"code","source":"# 평균 ctr\nlabel_distribution = dataset.groupby('label').size()\nprint(label_distribution)\navg_ctr = float(label_distribution[1] / label_distribution.sum())\navg_ctr","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.024066Z","iopub.execute_input":"2021-12-12T12:13:55.024513Z","iopub.status.idle":"2021-12-12T12:13:55.045802Z","shell.execute_reply.started":"2021-12-12T12:13:55.024475Z","shell.execute_reply":"2021-12-12T12:13:55.044919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모델을 돌릴 때 information gain도 함께 측정하기 위해 평균 ctr을 구해봅니다.  \n0.03은 3%입니다.","metadata":{}},{"cell_type":"code","source":"train = dataset[:575192]\ntest = dataset[575192:]\ntest.reset_index(drop = True, inplace = True)\n\ndel og_train\ndel og_test","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.047345Z","iopub.execute_input":"2021-12-12T12:13:55.04825Z","iopub.status.idle":"2021-12-12T12:13:55.053534Z","shell.execute_reply.started":"2021-12-12T12:13:55.048213Z","shell.execute_reply":"2021-12-12T12:13:55.05275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"원본 train/test dataset과 동일하게 8:2로 다시 자릅니다.  \nconcat할 때 세로 방향으로 붙였기 때문에 row 수만 동일하게 자르면 원본 데이터셋과 동일한 구성이 됩니다.","metadata":{}},{"cell_type":"code","source":"X_train = train.drop('label', axis = 1)\ny_train = train['label']\nX_test = test.drop('label', axis = 1)\ny_test = test['label']\n\ndel train\ndel test\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.054906Z","iopub.execute_input":"2021-12-12T12:13:55.05576Z","iopub.status.idle":"2021-12-12T12:13:55.124474Z","shell.execute_reply.started":"2021-12-12T12:13:55.055726Z","shell.execute_reply":"2021-12-12T12:13:55.123578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save & download\ndef save_download(model, name):\n    joblib.dump(model, './' + name)\n\n# load \n# loaded_model = joblib.load('./knn_model.pkl')\n# score = loaded_model.score(X,y)\n# print('정확도: {score:.3f}'.format(score=score))","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.125984Z","iopub.execute_input":"2021-12-12T12:13:55.126325Z","iopub.status.idle":"2021-12-12T12:13:55.13193Z","shell.execute_reply.started":"2021-12-12T12:13:55.126287Z","shell.execute_reply":"2021-12-12T12:13:55.13092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Define\n\nxgbm = xgb.XGBClassifier(learning_rate=0.1,             \n                         n_estimators = 1000,           \n                         max_depth = 9,                 \n                         min_child_weight = 1,          \n                         gamma = 0.3,                    \n                         n_jobs = -1,                   \n                         eval_metric = 'logloss',       \n                         objective = 'binary:logistic', \n                         use_label_encoder = False)     \n\nlgbm = lgb.LGBMClassifier(learning_rate = 0.09,\n                          n_estimators = 2000,\n                          max_depth = 8,\n                          num_leaves = 50,\n                          min_child_weight = 1,\n                          subsample = 0.5,\n                          colsample_bytree = 0.5,\n                          n_jobs = -1,\n                          objective = 'binary',\n                          metric = 'binary_logloss',)\n\n\ncbm = CatBoostClassifier(learning_rate = 0.05,\n                         n_estimators = 1600,\n                         max_depth = 9)\n\nrfm = RandomForestClassifier(n_estimators = 2000,\n                             min_samples_leaf = 4,\n                             min_samples_split = 8,)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.133803Z","iopub.execute_input":"2021-12-12T12:13:55.134116Z","iopub.status.idle":"2021-12-12T12:13:55.149406Z","shell.execute_reply.started":"2021-12-12T12:13:55.134081Z","shell.execute_reply":"2021-12-12T12:13:55.14843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"모델을 정의하고 각 모델의 파라미터를 튜닝합니다.\n각 모델을 default 파라미터로 설정한 후에 첫 학습을 돌리고 loss를 확인합니다.  \n이 후 각 모델별로 gridsearchCV에 하이퍼 파라미터 범위를 명시해서 튜닝을 시작합니다.  \ncatboost의 경우 파라미터 최적화가 잘 되어 있는 모델이었기 때문에 많은 하이퍼 파라미터를 사용하는 것 보다 핵심 파라미터만 튜닝하는 것이 성능이 더 좋았습니다.  \nrandomforest는 트리 수를 최대한 늘리고 분기 조건과 leaf node의 최소 데이터 개수를 조정해가며 overfitting을 제어했습니다.\n","metadata":{}},{"cell_type":"code","source":"# K-Fold for CV\nkf = KFold(random_state = 42,\n           n_splits = 2,\n           shuffle = True)\n\n\n# Model's hyperparameters for GridSearchCV\n# rf_params ={}\n\n# lgb_params ={}\n\nxgb_params ={}\n\n# cb_params = {} ","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.150887Z","iopub.execute_input":"2021-12-12T12:13:55.15131Z","iopub.status.idle":"2021-12-12T12:13:55.159761Z","shell.execute_reply.started":"2021-12-12T12:13:55.151273Z","shell.execute_reply":"2021-12-12T12:13:55.1589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GridSearchCV\ngcv = GridSearchCV(estimator = lgbm,\n                   param_grid = lgb_params,\n                   cv = kf,\n                   n_jobs = -1,\n                   verbose = 3,\n                   scoring = 'neg_log_loss') \n\ngcv.fit(X_train, y_train)\n\nprint(gcv.best_params_)\nprint(gcv.best_score_)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.161277Z","iopub.execute_input":"2021-12-12T12:13:55.161775Z","iopub.status.idle":"2021-12-12T12:13:55.544899Z","shell.execute_reply.started":"2021-12-12T12:13:55.161738Z","shell.execute_reply":"2021-12-12T12:13:55.54297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"neg_log_loss가 쓰인 이유는 gridsearchCV에서는 스코어가 높을수록 좋다라고 판단하기 때문입니다. 하지만 log_loss는 낮을수록 좋은 metric이기 때문에 -1를 곱해서 높을수록 좋다고 판단하도록 만든 것입니다.","metadata":{}},{"cell_type":"code","source":"# LightGBM\nlgbm.fit(X_train, y_train)\n\n\nprior = log_loss(y_train, [avg_ctr]*len(y_train))\n\n# pred & loss\npred_proba = lgbm.predict_proba(X_test)\npred = lgbm.predict(X_test)\nlogloss = log_loss(y_test, pred_proba)\nAUC = roc_auc_score(y_test, pred)\n\n# relative information gain\nrig = (prior - logloss) / prior\n\n\nprint(f'test AUC : {AUC}')\nprint(f'test log loss : {logloss}')\nprint(f'rig : {rig}')\nprint('\\n')\n\n# feature importance plot\nprint('LightGBM : feature importance')\nfig, ax = plt.subplots(figsize = (14, 7))\nlgb.plot_importance(lgbm, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:14:07.917615Z","iopub.execute_input":"2021-12-12T12:14:07.918409Z","iopub.status.idle":"2021-12-12T12:16:39.117518Z","shell.execute_reply.started":"2021-12-12T12:14:07.918357Z","shell.execute_reply":"2021-12-12T12:16:39.116796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_download(lgbm, 'lgbm_0.0927')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.548329Z","iopub.status.idle":"2021-12-12T12:13:55.548764Z","shell.execute_reply.started":"2021-12-12T12:13:55.548514Z","shell.execute_reply":"2021-12-12T12:13:55.548549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# XGBoost\nxgbm.fit(X_train, y_train)\n\n\nprior = log_loss(y_train, [avg_ctr]*len(y_train))\n\n# pred & loss\npred_proba = xgbm.predict_proba(X_test)\npred = xgbm.predict(X_test)\nlogloss = log_loss(y_test, pred_proba)\nAUC = roc_auc_score(y_test, pred)\n\n# relative information gain\nrig = (prior - logloss) / prior\n\n\nprint(f'test AUC : {AUC}')\nprint(f'test log loss : {logloss}')\nprint(f'rig : {rig}')\nprint('\\n')\n\n\n# feature importance plot\nprint('XGBoost : feature importance')\nfig, ax = plt.subplots(figsize = (14, 7))\nxgb.plot_importance(xgbm, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:24:17.233129Z","iopub.execute_input":"2021-12-12T12:24:17.233814Z","iopub.status.idle":"2021-12-12T12:53:05.349749Z","shell.execute_reply.started":"2021-12-12T12:24:17.233775Z","shell.execute_reply":"2021-12-12T12:53:05.348935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_download(xgbm, 'xgbm_auc_0.5577')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.551879Z","iopub.status.idle":"2021-12-12T12:13:55.552299Z","shell.execute_reply.started":"2021-12-12T12:13:55.552085Z","shell.execute_reply":"2021-12-12T12:13:55.552107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CatBoost\ncbm.fit(X_train, y_train, verbose = False)\n\n\nprior = log_loss(y_train, [avg_ctr]*len(y_train))\n\n# pred & loss\npred_proba = cbm.predict_proba(X_test)\npred = cbm.predict(X_test)\nlogloss = log_loss(y_test, pred_proba)\nAUC = roc_auc_score(y_test, pred)\n\n# relative information gain\nrig = (prior - logloss) / prior\n\n\nprint(f'test AUC : {AUC}')\nprint(f'test log loss : {logloss}')\nprint(f'rig : {rig}')\nprint('\\n')\n\n\n# print('CatBoost : feature importance')\n\n# feature importance plot\ndef plot_feature_importance(importance,names,model_type):\n    \n    feature_importance = np.array(importance)\n    feature_names = np.array(names)\n    \n    data={'feature_names':feature_names,'feature_importance':feature_importance}\n    fi_df = pd.DataFrame(data)\n    \n    fi_df.sort_values(by=['feature_importance'], ascending=False,inplace=True)\n\n    plt.figure(figsize=(10,8))\n\n    sns.barplot(x=fi_df['feature_importance'], y=fi_df['feature_names'])\n\n    plt.title(model_type + ' Feature Importance')\n    plt.xlabel('Feature Importance')\n    plt.ylabel('Feature Names')\n    \n# plot_feature_importance(catboost.get_feature_importance(),X_test.columns,'CATBOOST')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:17:16.1884Z","iopub.execute_input":"2021-12-12T12:17:16.188862Z","iopub.status.idle":"2021-12-12T12:22:48.854243Z","shell.execute_reply.started":"2021-12-12T12:17:16.188823Z","shell.execute_reply":"2021-12-12T12:22:48.853469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_download(cbm, 'cbm_0.0918')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.556311Z","iopub.status.idle":"2021-12-12T12:13:55.556601Z","shell.execute_reply.started":"2021-12-12T12:13:55.556447Z","shell.execute_reply":"2021-12-12T12:13:55.556466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RandomForestClassifier\nrfm.fit(X_train, y_train)\n\n\nprior = log_loss(y_train, [avg_ctr]*len(y_train))\n\n# pred & loss\npred_proba = rfm.predict_proba(X_test)\npred = rfm.predict(X_test)\nlogloss = log_loss(y_test, pred_proba)\nAUC = roc_auc_score(y_test, pred)\n\n# relative information gain\nrig = (prior - logloss) / prior\n\n\nprint(f'test AUC : {AUC}')\nprint(f'test log loss : {logloss}')\nprint(f'rig : {rig}')\nprint('\\n')\n# print('RandomForestClassifier : feature importance')\n\n# feature importance plot\n# fig, ax = plt.subplots(figsize = (14, 7))\n# lgb.plot_importance(lgbm, ax=ax)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:53:42.436872Z","iopub.execute_input":"2021-12-12T12:53:42.437502Z","iopub.status.idle":"2021-12-12T13:24:52.066586Z","shell.execute_reply.started":"2021-12-12T12:53:42.43745Z","shell.execute_reply":"2021-12-12T13:24:52.065734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_download(rfm, 'rfm_0.0942')","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.560157Z","iopub.status.idle":"2021-12-12T12:13:55.56073Z","shell.execute_reply.started":"2021-12-12T12:13:55.5605Z","shell.execute_reply":"2021-12-12T12:13:55.560526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 임의 유저로 테스트해보자.\n\n# 모델에 사용한 dataset에서 유저 정보를 드랍한다.\nseonwoo_dataset = dataset.drop(['c_user_gender', 'c_user_age',\n       'user_following_count', 'user_pay_count', 'user_parcel_post_count',\n       'user_transfer_count', 'user_chat_count'], axis = 1)\n\n# 임의 유저의 정보를 추가한다.\nseonwoo_dataset['c_user_gender'] = 1\nseonwoo_dataset['c_user_age'] = 34\nseonwoo_dataset['user_following_count'] = 0\nseonwoo_dataset['user_pay_count'] = 0\nseonwoo_dataset['user_parcel_post_count'] = 0\nseonwoo_dataset['user_transfer_count'] = 0\nseonwoo_dataset['user_chat_count'] = 0\n\nseonwoo_dataset_label = seonwoo_dataset['label']\nseonwoo_dataset.drop('label', axis = 1, inplace = True)\nseonwoo_dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.561938Z","iopub.status.idle":"2021-12-12T12:13:55.562628Z","shell.execute_reply.started":"2021-12-12T12:13:55.562356Z","shell.execute_reply":"2021-12-12T12:13:55.562383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"실제 추천을 하기 위해 임의 유저의 데이터를 입력하는 부분입니다.  \n학습에 사용된 데이터셋에서 유저 정보와 관련된 컬럼을 모두 드랍하고 대신 임의의 유저 정보를 입력해서 컬럼을 다시 채웁니다.  \n나머지 컬럼의 값들은 모두 동일하기 때문에 unseen data(유저 정보)를 넣어주고 모델이 추론하는 것과 같습니다.    \n현재 cell은 신규 유저를 기준으로 예측을 하기 위한 유저 정보를 입력한 것입니다.","metadata":{}},{"cell_type":"code","source":"compression_opts = dict(method='zip',\n                        archive_name='가상인물데이터2.csv')  \nseonwoo_dataset.to_csv('가상인물데이터2.zip', index=False,\n          compression=compression_opts)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.563851Z","iopub.status.idle":"2021-12-12T12:13:55.564454Z","shell.execute_reply.started":"2021-12-12T12:13:55.564184Z","shell.execute_reply":"2021-12-12T12:13:55.56421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seonwoo_dataset.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.5657Z","iopub.status.idle":"2021-12-12T12:13:55.566309Z","shell.execute_reply.started":"2021-12-12T12:13:55.566084Z","shell.execute_reply":"2021-12-12T12:13:55.566109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 임의 유저에 대해 prediction을 해보자.\nprobs = xgbm.predict_proba(seonwoo_dataset)\n\n# 계산된 확률을 dataframe에 추가하자.\nseonwoo_dataset['probs'] = probs[:, 1]\n\nseonwoo_dataset","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.567472Z","iopub.status.idle":"2021-12-12T12:13:55.568148Z","shell.execute_reply.started":"2021-12-12T12:13:55.567866Z","shell.execute_reply":"2021-12-12T12:13:55.56789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"AUC상 가장 성능이 좋았던 학습된 xgboost 모델을 이용해서 위에서 만든 임의 유저 데이터셋을 예측합니다.  \n예측된 값(확률 값)을 컬럼에 추가합니다.  \n확률이 높은 순으로 top-k개를 잘라내야 하기 때문입니다.","metadata":{}},{"cell_type":"code","source":"compression_opts = dict(method='zip',\n                        archive_name='가상인물데이터2 예측 결과.csv')  \nseonwoo_dataset.to_csv('가상인물데이터2 예측 결과.zip', index=False,\n          compression=compression_opts)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.569293Z","iopub.status.idle":"2021-12-12T12:13:55.569817Z","shell.execute_reply.started":"2021-12-12T12:13:55.569592Z","shell.execute_reply":"2021-12-12T12:13:55.569617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seonwoo_loss = log_loss(seonwoo_dataset_label, probs)\nseonwoo_loss","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.571082Z","iopub.status.idle":"2021-12-12T12:13:55.571637Z","shell.execute_reply.started":"2021-12-12T12:13:55.571399Z","shell.execute_reply":"2021-12-12T12:13:55.571423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"임의 유저에 대해 진행한 prediction의 logloss를 확인합니다.","metadata":{}},{"cell_type":"code","source":"# 임의 유저가 보게 될 확률이 높은 광고주 top-3\n\nrecommended = seonwoo_dataset.sort_values(by = ['probs'], ascending = False).drop_duplicates(['advertiser_id'], keep = 'first').head(3)\nrecommended","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.572834Z","iopub.status.idle":"2021-12-12T12:13:55.573425Z","shell.execute_reply.started":"2021-12-12T12:13:55.573181Z","shell.execute_reply":"2021-12-12T12:13:55.573206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"우리 데이터셋의 특성상 top-n개를 뽑으면 같은 동일한 광고주가 추천될 가능성을 제외하기 위해 advertiser_id 중복을 제거하고 내림차순 top-3를 뽑습니다.","metadata":{}},{"cell_type":"code","source":"compression_opts = dict(method='zip',\n                        archive_name='가상인물데이터2 top-3 노편집.csv')  \nrecommended.to_csv('가상인물데이터2 top-3 노편집.zip', index=False,\n          compression=compression_opts)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.574601Z","iopub.status.idle":"2021-12-12T12:13:55.575258Z","shell.execute_reply.started":"2021-12-12T12:13:55.575033Z","shell.execute_reply":"2021-12-12T12:13:55.575058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rec_adv = pd.DataFrame(recommended['advertiser_id'])\nrec_adv","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.576436Z","iopub.status.idle":"2021-12-12T12:13:55.577135Z","shell.execute_reply.started":"2021-12-12T12:13:55.576795Z","shell.execute_reply":"2021-12-12T12:13:55.57682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"top-3까지 잘린 데이터프레임에서 advertiser_id만 뽑아내면 임의의 유저가 볼 확률이 높은 광고주 top-3 명단이 만들어집니다.","metadata":{}},{"cell_type":"code","source":"# rec_adv.to_csv(index = False)\n\ncompression_opts = dict(method='zip',\n                        archive_name='out2.csv')  \nrec_adv.to_csv('xgb_output2.zip', index=False,\n          compression=compression_opts)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.578339Z","iopub.status.idle":"2021-12-12T12:13:55.578929Z","shell.execute_reply.started":"2021-12-12T12:13:55.578651Z","shell.execute_reply":"2021-12-12T12:13:55.578708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot\n\nauc_df = pd.DataFrame({\"RandomForest\": [0.5061],\n                       \"LightGBM\" : [0.5420],\n                       'XGBoost' : [0.5577],\n                       'CatBoost' : [0.5167]})\n\nauc_df.rename(index = {0:'AUC'}, inplace = True)\nauc_df\n# sns.lineplot(data = auc_df)","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.580154Z","iopub.status.idle":"2021-12-12T12:13:55.58079Z","shell.execute_reply.started":"2021-12-12T12:13:55.580561Z","shell.execute_reply":"2021-12-12T12:13:55.580587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"각 모델의 AUC score를 기준으로 plot을 만들기 위해 데이터프레임을 만듭니다.  ","metadata":{}},{"cell_type":"code","source":"# plot\nsns.set_style('whitegrid')\nsns.set(rc = {'figure.figsize' : (15, 8)},\n        font_scale = 2)\nsns.lineplot(data = auc_df.T.reset_index().rename(columns = {'index' : 'model'}), \n             x = 'model', \n             y = 'AUC',\n             color = 'r',\n             linewidth = 3.5)\nplt.title('AUC Score by Gradient Boosting Model')\nplt.grid(True)\n\nplt.savefig('auc_plot.png')\n\n","metadata":{"execution":{"iopub.status.busy":"2021-12-12T12:13:55.582025Z","iopub.status.idle":"2021-12-12T12:13:55.582558Z","shell.execute_reply.started":"2021-12-12T12:13:55.582326Z","shell.execute_reply":"2021-12-12T12:13:55.58235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}